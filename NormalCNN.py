# -*- coding: utf-8 -*-
"""
Created on Fri Apr 20 09:21:11 2018

@author: Karim El Guermai
"""
#%%
#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
from keras.models import Model
from keras.layers import  Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras import backend as K
from keras.applications.inception_v3 import preprocess_input
from keras.preprocessing.image import ImageDataGenerator
from keras.optimizers import SGD
from keras.losses import categorical_crossentropy
from keras.layers import Dense, GlobalAveragePooling2D
import os
#this is used for plotting the model into a pnj file
os.environ["PATH"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'
from keras.callbacks import ModelCheckpoint
from keras.callbacks import EarlyStopping
from keras.models import Sequential
#from keras.utils import plot_model

import numpy as np
import matplotlib.pyplot as plt

#%% get subfolder's count of a folder
def get_num_subfolders(path):
    if not os.path.exists(path):
        return 0
    return sum([len(d) for r, d , files in os.walk(path)])
#%% get files's count number in a folder and in its subfolders
def get_num_files(path):
    if not os.path.exists(path):
        return 0
    return sum([len(files) for r, d , files in os.walk(path)])

#%% artificially increasing number of training and validation images
def create_img_generator():
    return ImageDataGenerator(
            preprocessing_function = preprocess_input,
            rotation_range = 30,
            width_shift_range = 0.2,
            height_shift_range = 0.2,
            shear_range = 0.2,
            zoom_range = 0.2,
            horizontal_flip= True )

 #connect the image generator to the source folder
 #store it in train_generator
def generateTrainingData():
    global train_generator
    train_generator = create_img_generator().flow_from_directory(
            train_dir,
            target_size = (Image_width, Image_height),
            color_mode='grayscale',
            batch_size =batch_size,
            seed = 42)   

#%%store it in validation_generator
def generateValidatingData():
    global validation_generator
    validation_generator = create_img_generator().flow_from_directory(
            validate_dir,
            target_size = (Image_width, Image_height),
    			color_mode='grayscale',
            batch_size =batch_size,
            seed = 42)  
#%%
def buildInceptionModel():
    global input_shape, model
    model = Sequential()
    #is you want to take the input as gray scale, make 1
    model.add(Conv2D(32, kernel_size=(3, 3), activation= 'relu',
                input_shape = (Image_width,Image_height,GRAYSCALE)))
    model.add(MaxPooling2D(pool_size = (2,2)))
    model.add(Conv2D(64, kernel_size=(3, 3), activation= 'relu'))
    model.add(MaxPooling2D(pool_size = (2,2)))
    model.add(Flatten())
    model.add(Dense(NUMBER_FC_NEURONS, activation = 'relu'))
    model.add(Dropout(0.5))
    model.add(Dense(num_classes, activation = 'softmax'))
    
#%%  as the problem is a categorical classification, we use categorical_crossentropy  
def compileModel():
    global model
    model.compile(optimizer= 'adam', loss= 'categorical_crossentropy',
                  metrics=['accuracy'])
   # plot_model(model, to_file="CNN_model.png", show_shapes=True, show_layer_names=True)
    #model.summary()
#%%       
def trainModel():
    #trainning and validation data are generated by training generator 
    #and validation generator
    global history_transfer_learning
    #adding checkpoint and EarlyStopping
    #checkpoint save the model after each epoch it the accuracy is the highest
    #checkpoint1 = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max',period=1)
    EarlyStop = EarlyStopping(monitor='val_acc', patience=20, mode='max')
	#callbacks_list = [EarlyStop,checkpoint1]  #no need for checkpoint for now
    callbacks_list = [EarlyStop]
    #--------------
    history_transfer_learning = model.fit_generator(
            train_generator,
            epochs=num_epoch,
            steps_per_epoch = num_train_samples //batch_size,
            validation_data = validation_generator,
            validation_steps = num_validate_samples // batch_size,
            callbacks=callbacks_list)
   
   # score = model.evaluate(train_generator, validation_generator, verbose=0)
   # print('Test loss:', score[0])
   # print('Test accuracy:', score[1])
#%% Main method
#global variables
GRAYSCALE = 1
Image_width, Image_height = 50,50
TRAINING_EPOCHS = 100
BATCH_SIZE = 30
NUMBER_FC_NEURONS = 1024
num_epoch= TRAINING_EPOCHS
batch_size = BATCH_SIZE
train_dir = r'C:\Users\Karim El Guermai\Desktop\PROGRAMMING\FinalProject\Karim\Gestures_splitten\train'
validate_dir = r'C:\Users\Karim El Guermai\Desktop\PROGRAMMING\FinalProject\Karim\Gestures_splitten\validate'
model = None
history_transfer_learning = None
validation_generator = train_generator = None
filepath= 'NormalCNNTest.h5'
#%%
# get num_files of train directory and validate directory
num_train_samples = get_num_files(train_dir)
num_classes = get_num_subfolders(train_dir)
num_validate_samples = get_num_files(validate_dir)
#%%
generateTrainingData()
#%%
generateValidatingData()
#%%
buildInceptionModel()
#%%
compileModel()
#%%
trainModel()
#%% activate this to save the model
#model.save("/output/karim_model.h5")

#%%predicting

